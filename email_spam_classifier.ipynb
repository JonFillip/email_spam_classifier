{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a757288",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c048a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 show scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2791e0fd",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Python ≥3.6 is required\n",
    "import sys\n",
    "assert sys.version_info\n",
    "sys.path.append('/Users/username/ml/ml_env/lib/python3.8/site-packages')\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "# import pandas as pd\n",
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"spam_filter\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92607a52",
   "metadata": {},
   "source": [
    "### Fetch Data (Emails) for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8b5b1ca",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DOWNLOAD_ROOT = \"http://spamassassin.apache.org/old/publiccorpus/\"\n",
    "HAM_URL = DOWNLOAD_ROOT + \"20030228_easy_ham.tar.bz2\" # Ham represents emails that are not classified as Spam. It is the negative class.\n",
    "SPAM_URL = DOWNLOAD_ROOT + \"20030228_spam.tar.bz2\" # Spam emails are emails that have been classified as spam. It is the positive class.\n",
    "SPAM_PATH = os.path.join(\"datasets\", \"spam\")\n",
    "\n",
    "def fetch_class_emails(ham_url=HAM_URL, spam_url=SPAM_URL, spam_path=SPAM_PATH):\n",
    "    if not os.path.isdir(spam_path):\n",
    "        os.makedirs(spam_path)\n",
    "    for filename, url in ((\"ham.tar.bz2\", ham_url), (\"spam.tar.bz2\", spam_url)):\n",
    "        path = os.path.join(spam_path, filename)\n",
    "        if not os.path.isfile(path):\n",
    "            urllib.request.urlretrieve(url, path)\n",
    "        tar_bz2_file = tarfile.open(path)\n",
    "        tar_bz2_file.extractall(path=spam_path)\n",
    "        tar_bz2_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ab2d2c7",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fetch_class_emails()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57c92a85",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load email data\n",
    "\n",
    "HAM_DIR = os.path.join(SPAM_PATH, \"easy_ham\")\n",
    "SPAM_DIR = os.path.join(SPAM_PATH, \"spam\")\n",
    "ham_filenames = [name for name in sorted(os.listdir(HAM_DIR)) if len(name) > 20]\n",
    "spam_filenames = [name for name in sorted(os.listdir(SPAM_DIR)) if len(name) > 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39f41ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ham_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "126d6957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spam_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69ddd152",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import email\n",
    "import email.policy\n",
    "\n",
    "def load_emails(is_spam, filename, spam_path=SPAM_PATH):\n",
    "    \"\"\"parses emails to handled headers, encoding, body, etc\"\"\"\n",
    "    directory = \"spam\" if is_spam else \"easy_ham\"\n",
    "    with open(os.path.join(spam_path, directory, filename), \"rb\") as f:\n",
    "        return email.parser.BytesParser(policy=email.policy.default).parse(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87f6ee89",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ham_emails = [load_emails(is_spam=False, filename=name) for name in ham_filenames]\n",
    "spam_emails = [load_emails(is_spam=True, filename=name) for name in spam_filenames]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a7c2db",
   "metadata": {},
   "source": [
    "To view content of the emails:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24ceb847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi,\n",
      "\n",
      "I think you need to give us a little more detailed information.\n",
      "\n",
      "On Wed, 04 Dec 2002, Gianni Ponzi wrote:\n",
      "\n",
      "> I have a prob when trying to install Linux (tried RedHat, Suse) on my\n",
      "> laptop. \n",
      "\n",
      "You get _exactly_ the same problem with Suse and RedHat, is that right?\n",
      "What versions of these have you used?\n",
      "\n",
      "> I can start the install but after about 2min, the whole pc just\n",
      "> dies.\n",
      "\n",
      "As in freezes, reboots?  Do you get any errors?\n",
      "\n",
      "> I know it's not a Linux prob and here is what I have encountered:\n",
      "> \n",
      "> I had the same problem when installing Win on it and eventually sorted it\n",
      "> out by disabling the infrared port. \n",
      "\n",
      "Did you disable it in the BIOS or in windows?\n",
      "\n",
      "> I'm guessing this might be same prob although I'm not sure. I am very new\n",
      "> to Linux so it's not that easy for me to work it out. I did manage to\n",
      "> follow the setup procedure at one stage (using images on disks) and it\n",
      "> cuts out either as it's trying to verify what CD-Rom I have or just after\n",
      "> (hence my suspicion of the infrared port again).\n",
      "\n",
      "1. What laptop is it?  What is the Processor and how much RAM does it have?\n",
      "\n",
      "2. You cannot simply boot off the cdrom?  It must be quite an old laptop\n",
      "then or else cdrom booting is disabled in the BIOS.  Is the cdrom external\n",
      "or strange in some way?\n",
      "\n",
      "Gavin\n",
      "\n",
      "-- \n",
      "Irish Linux Users' Group: ilug@linux.ie\n",
      "http://www.linux.ie/mailman/listinfo/ilug for (un)subscription information.\n",
      "List maintainer: listmaster@linux.ie\n"
     ]
    }
   ],
   "source": [
    "print(ham_emails[-1].get_content().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76de7b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A POWERHOUSE GIFTING PROGRAM You Don't Want To Miss! \n",
      " \n",
      "  GET IN WITH THE FOUNDERS! \n",
      "The MAJOR PLAYERS are on This ONE\n",
      "For ONCE be where the PlayerS are\n",
      "This is YOUR Private Invitation\n",
      "\n",
      "EXPERTS ARE CALLING THIS THE FASTEST WAY \n",
      "TO HUGE CASH FLOW EVER CONCEIVED\n",
      "Leverage $1,000 into $50,000 Over and Over Again\n",
      "\n",
      "THE QUESTION HERE IS:\n",
      "YOU EITHER WANT TO BE WEALTHY \n",
      "OR YOU DON'T!!!\n",
      "WHICH ONE ARE YOU?\n",
      "I am tossing you a financial lifeline and for your sake I \n",
      "Hope you GRAB onto it and hold on tight For the Ride of youR life!\n",
      "\n",
      "Testimonials\n",
      "\n",
      "Hear what average people are doing their first few days:\n",
      "�We've received 8,000 in 1 day and we are doing that over and over again!' Q.S. in AL\n",
      " �I'm a single mother in FL and I've received 12,000 in the last 4 days.� D. S. in FL\n",
      "�I was not sure about this when I sent off my $1,000 pledge, but I got back $2,000 the very next day!� L.L. in KY\n",
      "�I didn't have the money, so I found myself a partner to work this with. We have received $4,000 over the last 2 days. \n",
      "I think I made the right decision; don't you?� K. C. in FL\n",
      "�I pick up $3,000 my first day and I  they gave me free leads and all the training, you can too!� J.W. in CA\n",
      "\n",
      "ANNOUNCING: We will CLOSE your sales for YOU! And Help you get a Fax Blast IMMEDIATELY Upon Your Entry!!!    YOU Make the MONEY!!!\n",
      "FREE LEADS!!! TRAINING!!!\n",
      "\n",
      "$$DON'T WAIT!!! CALL NOW $$\n",
      "FAX BACK TO: 1-800-421-6318 OR Call 1-800-896-6568 \n",
      "\n",
      "Name__________________________________Phone___________________________________________\n",
      "\n",
      "Fax_____________________________________Email____________________________________________\n",
      "\n",
      "Best Time To Call_________________________Time Zone________________________________________\n",
      "\n",
      "This message is sent in compliance of the new e-mail bill. \"Per Section 301, Paragraph (a)(2)(C) of S. 1618, further transmissions by the sender of this email may be stopped, at no cost to you, by sending a reply to this email address with the word \"REMOVE\" in the subject line. Errors, omissions, and exceptions excluded.\n",
      " \n",
      "This is NOT spam! I have compiled this list from our Replicate Database, relative to Seattle Marketing Group, The Gigt, or Turbo Team for the sole purpose of these communications. Your continued inclusion is ONLY by your gracious permission. If you wish to not receive this mail from me, please send an email to tesrewinter@yahoo.com with \"Remove\" in the subject and you will be deleted immediately.\n"
     ]
    }
   ],
   "source": [
    "print(spam_emails[5].get_content().strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40dc6ec",
   "metadata": {},
   "source": [
    "Some emails have multiple parts, including photos and attachments (which can have their own attachments). Let's have a gander at some of the sorts of structures we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db11e3ed",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_email_struct(email):\n",
    "    \"\"\"Gets the structure of the email passed as an arg\"\"\"\n",
    "    if isinstance(email, str):\n",
    "        return email\n",
    "    payload = email.get_payload()\n",
    "    if isinstance(payload, list):\n",
    "        return \"multipart({})\".format(\", \".join([\n",
    "            get_email_struct(sub_email) \n",
    "            for sub_email in payload\n",
    "        ]))\n",
    "    else:\n",
    "        return email.get_content_type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6b36520",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def struct_counter(emails):\n",
    "    structs = Counter()\n",
    "    for email in emails:\n",
    "        struct = get_email_struct(email)\n",
    "        structs[struct] += 1\n",
    "    return structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "185bdece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('text/plain', 2408),\n",
       " ('multipart(text/plain, application/pgp-signature)', 66),\n",
       " ('multipart(text/plain, text/html)', 8),\n",
       " ('multipart(text/plain, text/plain)', 4),\n",
       " ('multipart(text/plain)', 3),\n",
       " ('multipart(text/plain, application/octet-stream)', 2),\n",
       " ('multipart(text/plain, text/enriched)', 1),\n",
       " ('multipart(text/plain, application/ms-tnef, text/plain)', 1),\n",
       " ('multipart(multipart(text/plain, text/plain, text/plain), application/pgp-signature)',\n",
       "  1),\n",
       " ('multipart(text/plain, video/mng)', 1),\n",
       " ('multipart(text/plain, multipart(text/plain))', 1),\n",
       " ('multipart(text/plain, application/x-pkcs7-signature)', 1),\n",
       " ('multipart(text/plain, multipart(text/plain, text/plain), text/rfc822-headers)',\n",
       "  1),\n",
       " ('multipart(text/plain, multipart(text/plain, text/plain), multipart(multipart(text/plain, application/x-pkcs7-signature)))',\n",
       "  1),\n",
       " ('multipart(text/plain, application/x-java-applet)', 1)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct_counter(ham_emails).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "333c4baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('text/plain', 218),\n",
       " ('text/html', 183),\n",
       " ('multipart(text/plain, text/html)', 45),\n",
       " ('multipart(text/html)', 20),\n",
       " ('multipart(text/plain)', 19),\n",
       " ('multipart(multipart(text/html))', 5),\n",
       " ('multipart(text/plain, image/jpeg)', 3),\n",
       " ('multipart(text/html, application/octet-stream)', 2),\n",
       " ('multipart(text/plain, application/octet-stream)', 1),\n",
       " ('multipart(text/html, text/plain)', 1),\n",
       " ('multipart(multipart(text/html), application/octet-stream, image/jpeg)', 1),\n",
       " ('multipart(multipart(text/plain, text/html), image/gif)', 1),\n",
       " ('multipart/alternative', 1)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct_counter(spam_emails).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74357a2",
   "metadata": {},
   "source": [
    "From the counter, we can observe that the ham emails have more plain text, while the spam emails have more html text/code in them. It is also observable that ham emails have PGP signatures, while no spam email have PGP signatures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22503401",
   "metadata": {},
   "source": [
    "**To examine email headers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69b33b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return-Path: <12a1mailbot1@web.de>\n",
      "Delivered-To: zzzz@localhost.spamassassin.taint.org\n",
      "Received: from localhost (localhost [127.0.0.1])\tby phobos.labs.spamassassin.taint.org (Postfix) with ESMTP id 136B943C32\tfor <zzzz@localhost>; Thu, 22 Aug 2002 08:17:21 -0400 (EDT)\n",
      "Received: from mail.webnote.net [193.120.211.219]\tby localhost with POP3 (fetchmail-5.9.0)\tfor zzzz@localhost (single-drop); Thu, 22 Aug 2002 13:17:21 +0100 (IST)\n",
      "Received: from dd_it7 ([210.97.77.167])\tby webnote.net (8.9.3/8.9.3) with ESMTP id NAA04623\tfor <zzzz@spamassassin.taint.org>; Thu, 22 Aug 2002 13:09:41 +0100\n",
      "From: 12a1mailbot1@web.de\n",
      "Received: from r-smtp.korea.com - 203.122.2.197 by dd_it7  with Microsoft SMTPSVC(5.5.1775.675.6);\t Sat, 24 Aug 2002 09:42:10 +0900\n",
      "To: dcek1a1@netsgo.com\n",
      "Subject: Life Insurance - Why Pay More?\n",
      "Date: Wed, 21 Aug 2002 20:31:57 -1600\n",
      "MIME-Version: 1.0\n",
      "Message-ID: <0103c1042001882DD_IT7@dd_it7>\n",
      "Content-Type: text/html; charset=\"iso-8859-1\"\n",
      "Content-Transfer-Encoding: quoted-printable\n"
     ]
    }
   ],
   "source": [
    "for header, value in spam_emails[0].items():\n",
    "    print(f\"{header}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6968820b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HK Email marking !'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_emails[-1][\"subject\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d1372b",
   "metadata": {},
   "source": [
    "### Spliting the data into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2005a7ea",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.array(ham_emails + spam_emails, dtype=object)\n",
    "y = np.array([0] * len(ham_emails) + [1] * len(spam_emails))\n",
    "\n",
    "data_train, data_test, label_train, label_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48d2b91",
   "metadata": {},
   "source": [
    "#### Preprocessing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "baf9e8c4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re #Request library\n",
    "from html import unescape \n",
    "\n",
    "def transform_html_to_text(html):\n",
    "    \"\"\"Takes html code and convert's it to text.\"\"\"\n",
    "    text = re.sub('<head.*?>.*?</head>', '', html, flags=re.M | re.S | re.I)\n",
    "    text = re.sub('<a\\s.*?>', ' HYPERLINK ', text, flags=re.M | re.S | re.I)\n",
    "    text = re.sub('<.*?>', '', text, flags=re.M | re.S)\n",
    "    text = re.sub(r'(\\s*\\n)+', '\\n', text, flags=re.M | re.S)\n",
    "    return unescape(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72d76aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HTML><HEAD><TITLE></TITLE><META http-equiv=\"Content-Type\" content=\"text/html; charset=windows-1252\"><STYLE>A:link {TEX-DECORATION: none}A:active {TEXT-DECORATION: none}A:visited {TEXT-DECORATION: none}A:hover {COLOR: #0033ff; TEXT-DECORATION: underline}</STYLE><META content=\"MSHTML 6.00.2713.1100\" name=\"GENERATOR\"></HEAD>\n",
      "<BODY text=\"#000000\" vLink=\"#0033ff\" link=\"#0033ff\" bgColor=\"#CCCC99\"><TABLE borderColor=\"#660000\" cellSpacing=\"0\" cellPadding=\"0\" border=\"0\" width=\"100%\"><TR><TD bgColor=\"#CCCC99\" valign=\"top\" colspan=\"2\" height=\"27\">\n",
      "<font size=\"6\" face=\"Arial, Helvetica, sans-serif\" color=\"#660000\">\n",
      "<b>OTC</b></font></TD></TR><TR><TD height=\"2\" bgcolor=\"#6a694f\">\n",
      "<font size=\"5\" face=\"Times New Roman, Times, serif\" color=\"#FFFFFF\">\n",
      "<b>&nbsp;Newsletter</b></font></TD><TD height=\"2\" bgcolor=\"#6a694f\"><div align=\"right\"><font color=\"#FFFFFF\">\n",
      "<b>Discover Tomorrow's Winners&nbsp;</b></font></div></TD></TR><TR><TD height=\"25\" colspan=\"2\" bgcolor=\"#CCCC99\"><table width=\"100%\" border=\"0\"  ...\n"
     ]
    }
   ],
   "source": [
    "spam_mails_html = [email for email in data_train[label_train==1]\n",
    "                    if get_email_struct(email) == \"text/html\"]\n",
    "sample_html_spam = spam_mails_html[7]\n",
    "print(sample_html_spam.get_content().strip()[:1000], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a59fe6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OTC\n",
      " Newsletter\n",
      "Discover Tomorrow's Winners \n",
      "For Immediate Release\n",
      "Cal-Bay (Stock Symbol: CBYI)\n",
      "Watch for analyst \"Strong Buy Recommendations\" and several advisory newsletters picking CBYI.  CBYI has filed to be traded on the OTCBB, share prices historically INCREASE when companies get listed on this larger trading exchange. CBYI is trading around 25 cents and should skyrocket to $2.66 - $3.25 a share in the near future.\n",
      "Put CBYI on your watch list, acquire a position TODAY.\n",
      "REASONS TO INVEST IN CBYI\n",
      "A profitable company and is on track to beat ALL earnings estimates!\n",
      "One of the FASTEST growing distributors in environmental & safety equipment instruments.\n",
      "Excellent management team, several EXCLUSIVE contracts.  IMPRESSIVE client list including the U.S. Air Force, Anheuser-Busch, Chevron Refining and Mitsubishi Heavy Industries, GE-Energy & Environmental Research.\n",
      "RAPIDLY GROWING INDUSTRY\n",
      "Industry revenues exceed $900 million, estimates indicate that there could be as much as $25 billi ...\n"
     ]
    }
   ],
   "source": [
    "print(transform_html_to_text(sample_html_spam.get_content())[:1000], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7109d46",
   "metadata": {},
   "source": [
    "Pipeline that takes an email and transforms its html code to plain text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e13b1c4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def email_to_text(email):\n",
    "    html = None\n",
    "    for part in email.walk():\n",
    "        cat_type = part.get_content_type()\n",
    "        if not cat_type in (\"text/plain\", \"text/html\"):\n",
    "            continue\n",
    "        try:\n",
    "            content = part.get_content()\n",
    "        except:\n",
    "            content = str(part.get_payload())\n",
    "        if cat_type == \"text/plain\":\n",
    "            return content\n",
    "        else:\n",
    "            html = content\n",
    "            \n",
    "        if html:\n",
    "            return transform_html_to_text(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "db1e323d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OTC\n",
      " Newsletter\n",
      "Discover Tomorrow's Winners \n",
      "For Immediate Release\n",
      "Cal-Bay (Stock Symbol: CBYI)\n",
      "Watch for analyst \"Strong Buy Recommendations\" and several advisory newsletters picking CBYI.  CBYI has filed to be traded on the OTCBB, share prices historically INCREASE when companies get listed on this larger trading exchange. CBYI is trading around 25 cents and should skyrocket to $2.66 - $3.25 a share in the near future.\n",
      "Put CBYI on your watch list, acquire a position TODAY.\n",
      "REASONS TO INVEST I ...\n"
     ]
    }
   ],
   "source": [
    "print(email_to_text(sample_html_spam)[:500], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8327e1df",
   "metadata": {},
   "source": [
    "### Using NLP to process to evaluate text in Ham and Spam emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9037eba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b06fda",
   "metadata": {},
   "source": [
    "One importnat method in NLP is _stemming_. Stemming in linguistic morphology and information retrieval, stemming is the process of reducing inflected words to their word stem, base or root form—generally a written word form. For example the word _write_ can morph into _writing, written, wright_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "480d6c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computations => comput\n",
      "Computation => comput\n",
      "Computing => comput\n",
      "Computed => comput\n",
      "Compute => comput\n",
      "Compulsive => compuls\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "stemmer = nltk.PorterStemmer()\n",
    "for word in (\"Computations\", \"Computation\", \"Computing\", \"Computed\", \"Compute\", \"Compulsive\"):\n",
    "        print(word, \"=>\", stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1b1e66",
   "metadata": {},
   "source": [
    "To replace URLs with the word \"URL\", import the `urlextract` library to create a regular expression for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0998ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install urlextract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0461b234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['app.kash.io', 'www.apple.com']\n"
     ]
    }
   ],
   "source": [
    "import urlextract\n",
    "\n",
    "url_extractor = urlextract.URLExtract()\n",
    "# print(url_extractor.find_urls(\"Find app.kash.io and www.apple.com\")) # Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f45be3",
   "metadata": {},
   "source": [
    "Building a Transfomer class that will convert emails to word counters. **Note**: sentences are split into words using Python's `split()` method, which uses whitespaces for word boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bae4e1c3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class EmailToWordCounterTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, strip_headers=True, lower_case=True, remove_punctuation=True,\n",
    "                 replace_urls=True, replace_numbers=True, stemming=True):\n",
    "        self.strip_headers = strip_headers\n",
    "        self.lower_case = lower_case\n",
    "        self.remove_punctuation = remove_punctuation\n",
    "        self.replace_urls = replace_urls\n",
    "        self.replace_numbers = replace_numbers\n",
    "        self.stemming = stemming\n",
    "        \n",
    "    def fit(self, data, label=None):\n",
    "        return self\n",
    "    def transform(self, data, label=None):\n",
    "        data_transformed = []\n",
    "        for email in data:\n",
    "            text = email_to_text(email) or \"\"\n",
    "            if self.lower_case:\n",
    "                text = text.lower()\n",
    "            if self.replace_urls and url_extractor is not None:\n",
    "                urls = list(set(url_extractor.find_urls(text)))\n",
    "                urls.sort(key=lambda url: len(url), reverse=True)\n",
    "                for url in urls:\n",
    "                    text = text.replace(url, \" URL \")\n",
    "            if self.replace_numbers:\n",
    "                text = re.sub(r'\\d+(?:\\.\\d*)?(?:[eE][+-]?\\d+)?', 'NUMBER', text)\n",
    "            if self.remove_punctuation:\n",
    "                text = re.sub(r'\\W+', ' ', text, flags=re.M)\n",
    "            word_counts = Counter(text.split())\n",
    "            if self.stemming and stemmer is not None:\n",
    "                stemmed_word_counts = Counter()\n",
    "                for word, count in word_counts.items():\n",
    "                    stemmed_word = stemmer.stem(word)\n",
    "                    stemmed_word_counts[stemmed_word] += count\n",
    "                word_counts = stemmed_word_counts\n",
    "            data_transformed.append(word_counts)\n",
    "        return np.array(data_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f19cfae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([Counter({'chuck': 1, 'murcko': 1, 'wrote': 1, 'stuff': 1, 'yawn': 1, 'r': 1}),\n",
       "       Counter({'the': 11, 'of': 9, 'and': 8, 'all': 3, 'christian': 3, 'to': 3, 'by': 3, 'jefferson': 2, 'i': 2, 'have': 2, 'superstit': 2, 'one': 2, 'on': 2, 'been': 2, 'ha': 2, 'half': 2, 'rogueri': 2, 'teach': 2, 'jesu': 2, 'some': 1, 'interest': 1, 'quot': 1, 'url': 1, 'thoma': 1, 'examin': 1, 'known': 1, 'word': 1, 'do': 1, 'not': 1, 'find': 1, 'in': 1, 'our': 1, 'particular': 1, 'redeem': 1, 'featur': 1, 'they': 1, 'are': 1, 'alik': 1, 'found': 1, 'fabl': 1, 'mytholog': 1, 'million': 1, 'innoc': 1, 'men': 1, 'women': 1, 'children': 1, 'sinc': 1, 'introduct': 1, 'burnt': 1, 'tortur': 1, 'fine': 1, 'imprison': 1, 'what': 1, 'effect': 1, 'thi': 1, 'coercion': 1, 'make': 1, 'world': 1, 'fool': 1, 'other': 1, 'hypocrit': 1, 'support': 1, 'error': 1, 'over': 1, 'earth': 1, 'six': 1, 'histor': 1, 'american': 1, 'john': 1, 'e': 1, 'remsburg': 1, 'letter': 1, 'william': 1, 'short': 1, 'again': 1, 'becom': 1, 'most': 1, 'pervert': 1, 'system': 1, 'that': 1, 'ever': 1, 'shone': 1, 'man': 1, 'absurd': 1, 'untruth': 1, 'were': 1, 'perpetr': 1, 'upon': 1, 'a': 1, 'larg': 1, 'band': 1, 'dupe': 1, 'import': 1, 'led': 1, 'paul': 1, 'first': 1, 'great': 1, 'corrupt': 1}),\n",
       "       Counter({'url': 4, 's': 3, 'group': 3, 'to': 3, 'in': 2, 'forteana': 2, 'martin': 2, 'an': 2, 'and': 2, 'we': 2, 'is': 2, 'yahoo': 2, 'unsubscrib': 2, 'y': 1, 'adamson': 1, 'wrote': 1, 'for': 1, 'altern': 1, 'rather': 1, 'more': 1, 'factual': 1, 'base': 1, 'rundown': 1, 'on': 1, 'hamza': 1, 'career': 1, 'includ': 1, 'hi': 1, 'belief': 1, 'that': 1, 'all': 1, 'non': 1, 'muslim': 1, 'yemen': 1, 'should': 1, 'be': 1, 'murder': 1, 'outright': 1, 'know': 1, 'how': 1, 'unbias': 1, 'memri': 1, 'don': 1, 't': 1, 'html': 1, 'rob': 1, 'sponsor': 1, 'number': 1, 'dvd': 1, 'free': 1, 'p': 1, 'join': 1, 'now': 1, 'from': 1, 'thi': 1, 'send': 1, 'email': 1, 'egroup': 1, 'com': 1, 'your': 1, 'use': 1, 'of': 1, 'subject': 1}),\n",
       "       Counter({'to': 6, 'anthoni': 2, 'i': 2, 'url': 2, 'a': 2, 'or': 2, 'it': 2, 'skip': 1, 'montanaro': 1, 'baxter': 1, 'accordingli': 1, 'wrote': 1, 'which': 1, 'is': 1, 'mostli': 1, 'ripoff': 1, 'of': 1, 'someth': 1, 'someon': 1, 'els': 1, 'post': 1, 'python': 1, 'dev': 1, 'within': 1, 'the': 1, 'last': 1, 'week': 1, 'so': 1, 'strip': 1, 'out': 1, 'sa': 1, 'gener': 1, 'header': 1, 'unless': 1, 've': 1, 'grown': 1, 'senil': 1, 'tonight': 1, 'you': 1, 'got': 1, 'from': 1, 'begin': 1, 'with': 1, 'pleas': 1, 'check': 1, 'in': 1, 'project': 1, 'and': 1, 'add': 1, 'short': 1, 'blurb': 1, 'readm': 1, 'txt': 1}),\n",
       "       Counter({'a': 8, 'the': 6, 'toni': 5, 'folder': 5, 'number': 4, 'in': 3, 'you': 3, 'exmh': 3, 'on': 2, 'to': 2, 'for': 2, 'link': 2, 'or': 2, 'move': 2, 'list': 2, 'mode': 2, 'hit': 2, 'and': 2, 'user': 2, 'fri': 1, 'sep': 1, 'nugent': 1, 'wrote': 1, 'essenc': 1, 'is': 1, 'there': 1, 'way': 1, 'mark': 1, 'destin': 1, 'messag': 1, 'without': 1, 'actual': 1, 'do': 1, 'i': 1, 'couldn': 1, 't': 1, 'see': 1, 'anyth': 1, 'obviou': 1, 'right': 1, 'click': 1, 'label': 1, 'main': 1, 'window': 1, 'key': 1, 'put': 1, 'into': 1, 'chang': 1, 'first': 1, 'time': 1, 'use': 1, 'it': 1, 'after': 1, 'start': 1, 'second': 1, 'go': 1, 'set': 1, 'target': 1, 'type': 1, 'few': 1, 'charact': 1, 'of': 1, 'name': 1, 'space': 1, 'autocomplet': 1, 'hal': 1, 'how': 1, 's': 1, 'spring': 1, 'shape': 1, 'up': 1, 'down': 1, 'under': 1, '_______________________________________________': 1, 'mail': 1, 'redhat': 1, 'com': 1, 'url': 1})],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_sample = data_train[:5]\n",
    "data_sample_wordcounts = EmailToWordCounterTransformer().fit_transform(feature_sample)\n",
    "data_sample_wordcounts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed3351b",
   "metadata": {},
   "source": [
    "Having got the word counts, it needs to be converted to vectors. To do this, create a new transformer whose `fit()` function will create the vocabulary (an ordered list of the most common terms) and whose `transform()` method will utilize the vocabulary to convert word counts to vectors. The result is a sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d2f4450b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "class WordCounterToVectorTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, vocabulary_size=1000):\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "    def fit(self, data, label=None):\n",
    "        total_count = Counter()\n",
    "        for word_count in data:\n",
    "            for word, count in word_count.items():\n",
    "                total_count[word] += min(count, 10)\n",
    "        most_common = total_count.most_common()[:self.vocabulary_size]\n",
    "        self.vocabulary_ = {word: index + 1 for index, (word, count) in enumerate(most_common)}\n",
    "        return self\n",
    "    def transform(self, data, label=None):\n",
    "        rows = []\n",
    "        cols = []\n",
    "        data_matrix = []\n",
    "        for row, word_count in enumerate(data):\n",
    "            for word, count in word_count.items():\n",
    "                rows.append(row)\n",
    "                cols.append(self.vocabulary_.get(word, 0))\n",
    "                data_matrix.append(count)\n",
    "        return csr_matrix((data_matrix, (rows, cols)), shape=(len(data), self.vocabulary_size + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8b98097d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5x11 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 39 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_transformer = WordCounterToVectorTransformer(vocabulary_size=10)\n",
    "data_sample_vectors = vocab_transformer.fit_transform(data_sample_wordcounts)\n",
    "data_sample_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1ee47f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [105,  11,   3,   8,   9,   1,   1,   1,   2,   2,   0],\n",
       "       [ 67,   0,   3,   2,   1,   0,   4,   2,   0,   1,   1],\n",
       "       [ 48,   1,   6,   1,   1,   2,   2,   1,   2,   0,   0],\n",
       "       [ 88,   6,   2,   2,   1,   8,   1,   3,   1,   2,   4]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sample_vectors.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b5cd20",
   "metadata": {},
   "source": [
    "What does this matrix mean? Well, the 105 in the second row, first column, means that the second email contains 105 words that are not part of the vocabulary. The 11 next to it means that the first word in the vocabulary is present 11 times in this email. The 3 next to it means that the second word is present 3 times, and so on. You can look at the vocabulary to know which words we are talking about. The first word is \"the\", the second word is \"of\", etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fee71326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'to': 2,\n",
       " 'and': 3,\n",
       " 'of': 4,\n",
       " 'a': 5,\n",
       " 'url': 6,\n",
       " 'in': 7,\n",
       " 'i': 8,\n",
       " 'on': 9,\n",
       " 'number': 10}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_transformer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc841f1f",
   "metadata": {},
   "source": [
    "### Training Spam Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5b462a9c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "preprocess_pipeline = Pipeline([\n",
    "    (\"email_to_wordcount\", EmailToWordCounterTransformer()),\n",
    "    (\"wordcount_to_vector\", WordCounterToVectorTransformer()),\n",
    "])\n",
    "\n",
    "data_train_transformed = preprocess_pipeline.fit_transform(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7e7ecb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.984) total time=   0.2s\n",
      "[CV] END ................................ score: (test=0.985) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=0.991) total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9866666666666667"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "log_clf = LogisticRegression(solver=\"lbfgs\", max_iter=1000, random_state=42)\n",
    "score = cross_val_score(log_clf, data_train_transformed, label_train, cv=3, verbose=3)\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6fbc5b",
   "metadata": {},
   "source": [
    "After training, the accuracy score returned is 98.7%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "377235c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 95.88%\n",
      "Recall: 97.89%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "data_test_transformed = preprocess_pipeline.transform(data_test)\n",
    "\n",
    "log_clf = LogisticRegression(solver=\"lbfgs\", max_iter=1000, random_state=42)\n",
    "log_clf.fit(data_train_transformed, label_train)\n",
    "\n",
    "label_pred = log_clf.predict(data_test_transformed)\n",
    "\n",
    "print(\"Precision: {:.2f}%\".format(100 * precision_score(label_test, label_pred)))\n",
    "print(\"Recall: {:.2f}%\".format(100 * recall_score(label_test, label_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d13853",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python38064bitf2c52784ce0145be85c43b82f14303e8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
